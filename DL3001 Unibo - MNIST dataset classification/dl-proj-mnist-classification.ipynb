{"metadata":{"colab":{"name":"mnistDense.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Mnist classification with NNs\nA first example of a simple Neural Network, applied to a well known dataset.","metadata":{"id":"B8wSwJnsjx5P"}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import utils\nimport numpy as np","metadata":{"id":"3wMZ2Ge6jw1E","execution":{"iopub.status.busy":"2024-03-16T14:11:32.889082Z","iopub.execute_input":"2024-03-16T14:11:32.889474Z","iopub.status.idle":"2024-03-16T14:11:32.898322Z","shell.execute_reply.started":"2024-03-16T14:11:32.889445Z","shell.execute_reply":"2024-03-16T14:11:32.896292Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Let us load the mnist dataset","metadata":{"id":"FDiNppLVkvqd"}},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = mnist.load_data()","metadata":{"id":"wL8GyC0Nk14o","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2fb5509c-8d5f-4a87-e9b8-3cf691280518","execution":{"iopub.status.busy":"2024-03-16T14:11:34.070879Z","iopub.execute_input":"2024-03-16T14:11:34.071318Z","iopub.status.idle":"2024-03-16T14:11:34.422250Z","shell.execute_reply.started":"2024-03-16T14:11:34.071276Z","shell.execute_reply":"2024-03-16T14:11:34.420919Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(\"pixel range is [{},{}]\".format(np.min(x_train),np.max(x_train)))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ijhDuLwwlQrI","outputId":"02bca448-0ef7-4c42-cb00-20a6874082d0","execution":{"iopub.status.busy":"2024-03-16T14:11:34.691442Z","iopub.execute_input":"2024-03-16T14:11:34.691972Z","iopub.status.idle":"2024-03-16T14:11:34.710258Z","shell.execute_reply.started":"2024-03-16T14:11:34.691935Z","shell.execute_reply":"2024-03-16T14:11:34.708812Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(60000, 28, 28)\npixel range is [0,255]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We normalize the input in the range [0,1]","metadata":{"id":"D01L64YcnWO5"}},{"cell_type":"code","source":"x_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train.shape, x_test.shape","metadata":{"id":"a8uA2Kp7mG9s","execution":{"iopub.status.busy":"2024-03-16T14:11:35.734356Z","iopub.execute_input":"2024-03-16T14:11:35.734842Z","iopub.status.idle":"2024-03-16T14:11:35.874391Z","shell.execute_reply.started":"2024-03-16T14:11:35.734806Z","shell.execute_reply":"2024-03-16T14:11:35.873043Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"((60000, 28, 28), (10000, 28, 28))"},"metadata":{}}]},{"cell_type":"markdown","source":"we need to change the shape of the data points to have 28*28 features which are the pixels of the image.","metadata":{}},{"cell_type":"code","source":"x_train = np.reshape(x_train,(60000,28*28))\nx_test = np.reshape(x_test,(10000,28*28))\nx_train.shape, x_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-16T14:11:36.746932Z","iopub.execute_input":"2024-03-16T14:11:36.747400Z","iopub.status.idle":"2024-03-16T14:11:36.759987Z","shell.execute_reply.started":"2024-03-16T14:11:36.747365Z","shell.execute_reply":"2024-03-16T14:11:36.758337Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"((60000, 784), (10000, 784))"},"metadata":{}}]},{"cell_type":"markdown","source":"The output of the network will be a proability distribution over the different categories. Similarly, we generate a ground truth distribution, and the training objective will consist in minimizing their distance (categorical crossentropy). The ground truth distribution is the so called \"categorical\" distribution: if x has label l, the corresponding categorical distribution has probaility 1 for the category l, and 0 for all the others.","metadata":{"id":"Yjrzmhgh3TZv"}},{"cell_type":"code","source":"print(y_train[0])\ny_train_cat = utils.to_categorical(y_train)\nprint(y_train_cat[0])\ny_test_cat = utils.to_categorical(y_test)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhzWUm0UnODb","outputId":"e0cf94cf-aabf-4d35-f84e-b481d72c10ec","execution":{"iopub.status.busy":"2024-03-16T14:11:37.450878Z","iopub.execute_input":"2024-03-16T14:11:37.451431Z","iopub.status.idle":"2024-03-16T14:11:37.463399Z","shell.execute_reply.started":"2024-03-16T14:11:37.451390Z","shell.execute_reply":"2024-03-16T14:11:37.462237Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"5\n[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This output says that for demonstrating the number \"5\", we need to have the corresponding value in the vector of 10 values to be equal to 1. Remember that, numbers in the dataset are 0 to 9. ","metadata":{}},{"cell_type":"markdown","source":"-----------","metadata":{}},{"cell_type":"markdown","source":"# FIRST NETWORK - Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"Our first Netwok just implements logistic regression.","metadata":{"id":"sfeZF3bUrFZf"}},{"cell_type":"markdown","source":"## Network Construction","metadata":{}},{"cell_type":"markdown","source":"Code Explanation:\n- __Input(shape=(784))__ : This line defines an input layer for the neural network. The shape parameter specifies the shape of the input data. In this case, it's set to (784), which suggests that the input data is expected to be a vector of length 784. This is commonly used in scenarios like image classification where each image is represented as a 784-dimensional vector (e.g., a flattened 28x28 image).\n- __Dense(10,activation='softmax')(xin)__ : This line defines a **fully connected (dense)** layer with **10 units** and a **softmax activation function**. The Dense layer connects every neuron in the previous layer (in this case, the input layer) to every neuron in the current layer. \n    - The softmax activation function is commonly used in the output layer of a classification model to obtain probabilities for each class. The output of this layer (res) represents the probabilities of the input belonging to each of the 10 classes.\n- __Model(inputs=xin,outputs=res)__ : This line creates a Keras Model by specifying the inputs and outputs of the model. **xin** is specified as the input, and **res** (the output of the dense layer) is specified as the output. \n    - This essentially constructs a neural network model that takes inputs through the defined input layer, passes them through the dense layer, and outputs the resulting probabilities through the softmax activation.","metadata":{}},{"cell_type":"code","source":"xin = Input(shape=(784, ))  ## We should define the number of the input data\nres = Dense(10,activation='softmax')(xin) \n\nmynet = Model(inputs=xin,outputs=res)","metadata":{"id":"hBJtMj2pqJiR","execution":{"iopub.status.busy":"2024-03-16T14:11:56.170415Z","iopub.execute_input":"2024-03-16T14:11:56.170892Z","iopub.status.idle":"2024-03-16T14:11:56.249971Z","shell.execute_reply.started":"2024-03-16T14:11:56.170857Z","shell.execute_reply":"2024-03-16T14:11:56.248975Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"mynet.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hXD5JT2ZrTJc","outputId":"36886e01-b9bb-4729-a1ad-257e43f09726","execution":{"iopub.status.busy":"2024-03-16T14:11:58.789768Z","iopub.execute_input":"2024-03-16T14:11:58.790528Z","iopub.status.idle":"2024-03-16T14:11:58.812728Z","shell.execute_reply.started":"2024-03-16T14:11:58.790487Z","shell.execute_reply":"2024-03-16T14:11:58.811502Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m7,850\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"__Summary__ explnation:\n- It shows a summery of this created network.\n- It says that the input layer consists of 784 input data which is equal to the number of features. \n    - The input layer does not have any parameter.\n- The second layer which is a dense layer has 10 neurons. Having said that, __dense__ referes to a fully connected neural network. So, here, having 10 neurons gives us 10*784 parameters + bias. The number of __bias__ equals to the number of neurons, so for the second layer which consists of 10 neurons we also have 10 bias values for each neuron. Since, __bias__ is considered parameters that can be configured, it increases out parameters to 7840+10 number. ","metadata":{}},{"cell_type":"markdown","source":"## Compile and Train ","metadata":{}},{"cell_type":"markdown","source":"After writing the code you provided, the typical next steps would involve compiling the model, specifying the loss function and optimization algorithm, and then training the model on the data.","metadata":{}},{"cell_type":"markdown","source":"**Compiling the Model**: Before training the model, you need to compile it. Compiling the model configures it for training by specifying the loss function, the optimizer, and optional metrics. So, we need to pass two mandatory arguments:\n*   the **optimizer**, in charge of governing the details of the backpropagation algorithm\n    - **optimizer='adam'**: This line specifies the Adam optimization algorithm, which is a popular choice for training neural networks due to its adaptive learning rate with momentum capabilities.\n*   the **loss function**\n    - **loss='categorical_crossentropy'**: This line specifies the loss function to optimize. __categorical_crossentropy__ is commonly used for the scenarios where we have categorical data as here. \n* Optionally, we can specify additional metrics, mostly meant for monitoring the training process.\n    - This specifies that you want to track the accuracy of the model during training.","metadata":{"id":"bcjcOz8yrk5X"}},{"cell_type":"code","source":"mynet.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"id":"7XK20mAFrrkQ","execution":{"iopub.status.busy":"2024-03-16T14:12:09.737418Z","iopub.execute_input":"2024-03-16T14:12:09.737937Z","iopub.status.idle":"2024-03-16T14:12:09.757887Z","shell.execute_reply.started":"2024-03-16T14:12:09.737901Z","shell.execute_reply":"2024-03-16T14:12:09.756691Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"**Training the Model:** After compiling the model, you can train it using the **fit** method by providing input data and corresponding target labels.\n\nFitting, just requires two arguments: training data and ground truth, that is x and y. Additionally we can specify epochs, batch_size, and many additional arguments.\n\nIn particular, passing validation data allow the training procedure to measure loss and metrics on the validation set at the end of each epoch.","metadata":{"id":"E58bT-Imvsw2"}},{"cell_type":"code","source":"mynet.fit(x_train, y_train_cat, shuffle=True, epochs=10, batch_size=32,validation_data=(x_test,y_test_cat))","metadata":{"id":"l2woDXbbr6ak","colab":{"base_uri":"https://localhost:8080/"},"outputId":"493cdebc-26fc-454f-d664-f1f1a60c1043","execution":{"iopub.status.busy":"2024-03-16T14:13:39.251758Z","iopub.execute_input":"2024-03-16T14:13:39.252205Z","iopub.status.idle":"2024-03-16T14:14:23.500552Z","shell.execute_reply.started":"2024-03-16T14:13:39.252174Z","shell.execute_reply":"2024-03-16T14:14:23.498812Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.6964 - val_accuracy: 0.9118 - val_loss: 0.3115\nEpoch 2/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.3157 - val_accuracy: 0.9220 - val_loss: 0.2797\nEpoch 3/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2880 - val_accuracy: 0.9253 - val_loss: 0.2722\nEpoch 4/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9242 - loss: 0.2696 - val_accuracy: 0.9266 - val_loss: 0.2692\nEpoch 5/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2710 - val_accuracy: 0.9268 - val_loss: 0.2666\nEpoch 6/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2585 - val_accuracy: 0.9247 - val_loss: 0.2675\nEpoch 7/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2545 - val_accuracy: 0.9257 - val_loss: 0.2674\nEpoch 8/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.2545 - val_accuracy: 0.9273 - val_loss: 0.2651\nEpoch 9/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2573 - val_accuracy: 0.9273 - val_loss: 0.2642\nEpoch 10/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9331 - loss: 0.2419 - val_accuracy: 0.9256 - val_loss: 0.2661\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a60c715bd00>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Another Network with 1 more layer\nIn the below code we have defined another network with one more Dense layer. We want to illustrate the impact of more layer on accuracy during the training.\n\nIn the below code you can see that we have provided more neurons in the second layer which gives us more parameters as it's described in the network summary. \n\n\n- We used __relu__ activation function for the second layer, and have used the __softmax__ activation function for the output layer as our output value is a categorical value.\n\n#### Construction\nConstructing the network:","metadata":{}},{"cell_type":"code","source":"xin = Input(shape=(784, ))\nx = Dense(128,activation='relu')(xin) \nres = Dense(10,activation='softmax')(x)\n\nmynet2 = Model(inputs=xin,outputs=res)","metadata":{"id":"k0mBuorMulG5","execution":{"iopub.status.busy":"2024-03-16T14:17:37.641226Z","iopub.execute_input":"2024-03-16T14:17:37.641646Z","iopub.status.idle":"2024-03-16T14:17:37.670321Z","shell.execute_reply.started":"2024-03-16T14:17:37.641617Z","shell.execute_reply":"2024-03-16T14:17:37.669441Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"mynet2.summary()","metadata":{"id":"SpMyvw7buzhT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bb66d7c4-39fa-4a9b-891d-ea7f1662bd41","execution":{"iopub.status.busy":"2024-03-16T14:18:52.268775Z","iopub.execute_input":"2024-03-16T14:18:52.269237Z","iopub.status.idle":"2024-03-16T14:18:52.293448Z","shell.execute_reply.started":"2024-03-16T14:18:52.269206Z","shell.execute_reply":"2024-03-16T14:18:52.292107Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Compile and Train\nWe compiled the network with the configuration same as the previous network.","metadata":{}},{"cell_type":"code","source":"mynet2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"id":"rYg0odW2u6cn","execution":{"iopub.status.busy":"2024-03-16T14:21:58.721917Z","iopub.execute_input":"2024-03-16T14:21:58.722376Z","iopub.status.idle":"2024-03-16T14:21:58.734620Z","shell.execute_reply.started":"2024-03-16T14:21:58.722344Z","shell.execute_reply":"2024-03-16T14:21:58.733306Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"Let's train it on the train data.","metadata":{}},{"cell_type":"code","source":"mynet2.fit(x_train,y_train_cat, shuffle=True, epochs=10, batch_size=32, validation_data=(x_test,y_test_cat))","metadata":{"id":"KDnzgIZVvGOm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cb25ba03-19bb-4197-de31-790e50c39cb5","execution":{"iopub.status.busy":"2024-03-16T14:22:21.576587Z","iopub.execute_input":"2024-03-16T14:22:21.577023Z","iopub.status.idle":"2024-03-16T14:23:40.106970Z","shell.execute_reply.started":"2024-03-16T14:22:21.576994Z","shell.execute_reply":"2024-03-16T14:23:40.105513Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8788 - loss: 0.4254 - val_accuracy: 0.9599 - val_loss: 0.1338\nEpoch 2/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.1149 - val_accuracy: 0.9726 - val_loss: 0.0913\nEpoch 3/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0774 - val_accuracy: 0.9727 - val_loss: 0.0870\nEpoch 4/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0558 - val_accuracy: 0.9772 - val_loss: 0.0731\nEpoch 5/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0419 - val_accuracy: 0.9791 - val_loss: 0.0718\nEpoch 6/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0309 - val_accuracy: 0.9777 - val_loss: 0.0748\nEpoch 7/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0264 - val_accuracy: 0.9771 - val_loss: 0.0760\nEpoch 8/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0201 - val_accuracy: 0.9786 - val_loss: 0.0797\nEpoch 9/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0177 - val_accuracy: 0.9790 - val_loss: 0.0793\nEpoch 10/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0141 - val_accuracy: 0.9798 - val_loss: 0.0824\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a609c2726e0>"},"metadata":{}}]},{"cell_type":"markdown","source":"The result shows an amazing improvement. WOW!","metadata":{"id":"UcUKxCzKwzG9"}},{"cell_type":"markdown","source":"## 3-Layered Network\nIn the next cell we have created another network wich has:\n- One more Dense layer\n- Sigmoid activation function\n- Adapted to work with Sparse Categorical Crossentropy\n\nWe have also plotted our network and its result.","metadata":{}},{"cell_type":"code","source":"xin = Input(shape=(784, ))\nx = Dense(128,activation='relu')(xin)\nx2 = Dense(128,activation='relu')(x)\nres = Dense(10,activation='softmax')(x2)\n\nmynet3 = Model(inputs=xin,outputs=res)\nmynet3.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T14:35:22.230599Z","iopub.execute_input":"2024-03-16T14:35:22.231123Z","iopub.status.idle":"2024-03-16T14:35:22.286913Z","shell.execute_reply.started":"2024-03-16T14:35:22.231090Z","shell.execute_reply":"2024-03-16T14:35:22.285991Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_17\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_11 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"**Change Explanation**:\n- __Difference between Categorical Crossentropy and Sparse Categorical Crossentropy__\n    - **Categorical Crossentropy:** This loss function is typically used when the target labels are one-hot encoded. \n        - One-hot encoding represents each class as a binary vector where only one element is nonzero, indicating the class index.\n        - The output of the model is compared to the one-hot encoded target labels.\n        - It calculates the cross-entropy loss between the predicted probabilities and the one-hot encoded target labels.\n        - Suitable for multi-class classification tasks when the classes are mutually exclusive.\n    - **Sparse Categorical Crossentropy:** This loss function is used when the target labels are integers, not one-hot encoded.\n        - Instead of one-hot encoding, each target label is represented as an integer indicating the class index directly.\n        - The output of the model is compared to the integer target labels.\n        - It calculates the cross-entropy loss between the predicted probabilities and the integer target labels.\n        - Convenient when you have a large number of classes, as it saves memory and computational resources by avoiding one-hot encoding.\n        - It's especially useful when dealing with large datasets where one-hot encoding could lead to memory issues.\n        \n- __Other Activation functions__\n    - There are several activation functions commonly used in neural networks, each with its own characteristics and suitability for different types of problems. Here are some of the most commonly used activation functions:\n    1. **Sigmoid**: The sigmoid function squashes the input values between 0 and 1. It's commonly used in the output layer of binary classification problems where the goal is to predict probabilities.\n$$\\text{sigmoid}(x) = \\frac{1}{1 + e^{-x}}$$\n    2. **ReLU (Rectified Linear Unit)**: ReLU sets all negative values to zero and leaves positive values unchanged. It's known for its simplicity and effectiveness in training deep neural networks.\n$$\\text{ReLU}(x) = \\max(0, x)$$\n    3. **Leaky ReLU**: Leaky ReLU is similar to ReLU but allows a small, positive gradient for negative input values, which can help with the vanishing gradient problem.\n$$ \\text{Leaky ReLU}(x) = \\begin{cases} x, & \\text{if } x > 0 \\\\ \\alpha x, & \\text{otherwise} \\end{cases} $$\n    4. **Tanh (Hyperbolic Tangent)**: Tanh squashes the input values between -1 and 1, making it zero-centered. It's often used in hidden layers of neural networks.\n$$\\text{tanh}(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$$\n    5. **Softmax**: Softmax is used in the output layer of multi-class classification problems. It converts raw scores (logits) into probabilities that sum up to 1.\n$$\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}}$$\n    6. **Linear**: Linear activation simply outputs the input value without applying any transformation. It's often used in the output layer for regression tasks.\n$$\\text{Linear}(x) = x$$","metadata":{}},{"cell_type":"code","source":"mynet3.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-16T14:37:02.231080Z","iopub.execute_input":"2024-03-16T14:37:02.231499Z","iopub.status.idle":"2024-03-16T14:37:02.242520Z","shell.execute_reply.started":"2024-03-16T14:37:02.231466Z","shell.execute_reply":"2024-03-16T14:37:02.240969Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"mynet3.fit(x_train, y_train, shuffle=True, epochs=10, batch_size=32, validation_data=(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T14:37:36.181593Z","iopub.execute_input":"2024-03-16T14:37:36.182283Z","iopub.status.idle":"2024-03-16T14:38:55.400384Z","shell.execute_reply.started":"2024-03-16T14:37:36.182245Z","shell.execute_reply":"2024-03-16T14:38:55.398870Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.0537 - val_accuracy: 0.9741 - val_loss: 0.0832\nEpoch 2/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0406 - val_accuracy: 0.9775 - val_loss: 0.0771\nEpoch 3/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0311 - val_accuracy: 0.9765 - val_loss: 0.0825\nEpoch 4/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0252 - val_accuracy: 0.9811 - val_loss: 0.0696\nEpoch 5/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0223 - val_accuracy: 0.9786 - val_loss: 0.0825\nEpoch 6/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0167 - val_accuracy: 0.9766 - val_loss: 0.0996\nEpoch 7/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0159 - val_accuracy: 0.9770 - val_loss: 0.0963\nEpoch 8/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0152 - val_accuracy: 0.9807 - val_loss: 0.0945\nEpoch 9/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0125 - val_accuracy: 0.9808 - val_loss: 0.0866\nEpoch 10/10\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.9782 - val_loss: 0.1016\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a6075759600>"},"metadata":{}}]}]}